# 2022-07-25
# hayley's code for computing artifact of a generative model
# GM = (Generator, Prior P_z) where G: Z -> X whose domain Z has the structure 
# in that its datapoints/masses are distributed according to the prob. distributionP_z

# General modules
from typing import Union, Optional, Callable, Tuple, List, Iterable
from genericpath import exists
import os, math, argparse
from pathlib import Path
# Imaging/ scientific modules
import numpy as np
import PIL
from PIL import Image

# Pytorch modules
import torch
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms

# Lightning module
from IPython.core.debugger import set_trace as breakpoint

from reprlearn.utils.misc import now2str, is_img_fp, read_image_as_tensor
from reprlearn.utils.np import show_npimgs
from reprlearn.utils.dists import squared_l2_dist
from reprlearn.visualize.utils import show_timgs

### >>> Helper
# scale conversions
# e.g., tanh image (-1.,1.) to 01timg (0., 1.) or to npimg in uint8[0,255]
def tanh_timg2npimg(timg: torch.Tensor):
    """Given a torch tensor `timg` (nc, h, w) in range [-1., 1.],
    scale each value x_in to: [0.,1.]
    
    Assume timg is in range [-1,1] (e.g., an rgb image generated by a generator
    whose last layer is tanh so that each pixel is squished to [-1,1].
    Use it to:
    (i) rescale [-1,1] to [0.,1.] and
    (ii) then to unit8 [0,255]
    so that it is properly scaled for plt.imshow() 
    """
    std = 0.5
    mean = 0.5
    timg = (timg.permute(1, 2, 0).cpu().numpy()*std) + mean
    npimg = np.uint8(timg*255.0) 
    
    return npimg


def save_tanhtimgs_as_png(timgs: Union[torch.Tensor, List], 
                        out_dir:Union[str,Path], 
                        start_index:int):
    """Save each tensor in batch_tsamples in [0.,1.] to a png image
    as `save_loc`/{start_index + i}.png
    """
    std = 0.5
    mean = 0.5
    timgs = ((timgs * std) + mean).cpu() 
    save_01timgs_as_png(timgs, out_dir, start_index) 
    

def save_01timgs_as_png(timgs: Union[torch.Tensor, List], 
                        out_dir:Union[str,Path], 
                        start_index:int):
    """Save each tensor in batch_tsamples in [0.,1.] to a png image
    as `save_loc`/{start_index + i}.png
    """
    for i in range(len(timgs)):
        index = i + start_index
        # img = (batch_timgs[i, :, :, :].permute(1, 2, 0).cpu().numpy()*std) + mean
        img = timgs[i, :, :, :].permute(1, 2, 0).cpu().numpy()

        img_pil = PIL.Image.fromarray(np.uint8(img*255.0))
        # img_pil.save(os.path.join(save_loc, "{}.png".format(index)), quality=95, subsampling=-1)
        img_pil.save(os.path.join(out_dir, "{}.png".format(index)))

    return
### <<< end Helpers

def estimate_projection(
    x_g: torch.Tensor,
    manifold: Iterable[torch.Tensor],
    metric: Optional[Callable]=None
) -> Tuple[torch.Tensor, float]:
    """Find a point x_p in `dset` that is closest to `x_g` using distance metric of
    `metric`
    todo:
    - [ ] "manifold" naming might be assuming extra structure. we are considering
    only a set of datapts on the (true) data manifold which we have access through
    the sample only
    """
    metric = metric or squared_l2_dist
    
    argmin = None
    d_min = np.inf
    for x in manifold:
        d_curr = metric(x_g, x)
        if d_curr < d_min:
            d_min = d_curr
            argmin = x
    return argmin, d_min.item()
        

def compute_artifact(
    x_g: torch.Tensor,
    manifold: Iterable[torch.Tensor],
    metric: Optional[Callable]=None
) -> torch.Tensor:
    """ Compute an artifact (diff. vector) of `x_g` wrt the reference manifold
    using the `metric` as the distance metric.
    Returns: artifact tensor of a := x_p - x_g
    
    """
    x_p, _ = estimate_projection(x_g, manifold, metric)
    return x_p - x_g
    
        
def compute_artifacts_in(
    fake_img_dir: Path,
    manifold: Iterable[torch.Tensor],
    out_dir: Path,
    metric: Optional[Callable]=None,
    show_trioplot: bool=False,
) -> torch.Tensor:
    """Compute artifacts of each image in fake_img_dir and save to out_dir"""
    for i, fp in enumerate(fake_img_dir.iterdir()):
        if not is_img_fp(fp):
            continue
            
        x_g = read_image_as_tensor(fp)
        art = compute_artifact(x_g, manifold, metric) 
        
        # save art as an image: 
        # - apply scaling [-1.,1.] to [0., 1.]
        try:
            out_stem = int(fp.stem)
        except ValueError:
            out_stem = i
        save_tanhtimgs_as_png(torch.stack([art]), out_dir=out_dir, start_index=out_stem)
    
        # show x_g, x_p, art
        if show_trioplot:
            x_p, _ = estimate_projection(x_g, manifold, metric)
            show_timgs([x_g, x_p, art], titles=['x_g', 'x_p', 'artifact'],
                    title=fp.stem, nrows=1)
    print('Done computing artifacts for: ', fake_img_dir) 


def compute_artifacts(
    fake_img_dir: Path,
    real_img_dir: Path,
    out_dir: Path,
    metric: Optional[Callable]=None,
    n_datapts: Optional[int]=None,
    show_trioplot: bool=False,
    transforms: Optional[Callable]=None,
) -> torch.Tensor:
    """Compute artifacts of each image in fake_img_dir and save to out_dir"""
    
    n_datapts = n_datapts or np.inf # to use all images in  real_img_dir
    
    # reference manifold
    manifold =[read_image_as_tensor(fp) for i, fp in enumerate(real_img_dir.iterdir())
        if i < n_datapts and is_img_fp(fp)]
    
    # compute artifacts
    for i, fp in enumerate(fake_img_dir.iterdir()):
        if not is_img_fp(fp):
            continue
            
        x_g = read_image_as_tensor(fp)
        art = compute_artifact(x_g, manifold, metric) 
        
        # save art as an image: 
        # - apply scaling [-1.,1.] to [0., 1.]
        try:
            out_stem = int(fp.stem)
        except ValueError:
            out_stem = i
        save_tanhtimgs_as_png(torch.stack([art]), out_dir=out_dir, start_index=out_stem)
    
        # show x_g, x_p, art
        if show_trioplot:
            x_p, _ = estimate_projection(x_g, manifold, metric)
            show_timgs([x_g, x_p, art], titles=['x_g', 'x_p', 'artifact'],
                    title=fp.stem, nrows=1)
            
    print('Done computing artifacts for: ', fake_img_dir) 
                             

# def estimate_projection_v1(x_g:torch.Tensor, img_dir:Path, d_x: Callable) -> Tuple[torch.Tensor, float]:
#     """
#     x_g: datapt generated by the generator
#     img_dir : path to the images on the data manifold
#     d_x: callable; metric on X to compute the distance between (x_g and x) for x in img_dir
#     """
#     # todo: test this function

#     min_d = np.inf
#     argmin = None
#     for img_fp in img_dir.iterdir():
#         x = read_image_as_tensor(img_fp)
#         curr_d = d_x(x_g, x)
        
#         if curr_d < min_d:
#             min_d = curr_d
#             argmin = x
#     return argmin, min_d

# def estimate_projection_v2(x_g:torch.Tensor, 
#                         dataset: Dataset, 
#                         n_datapts: int,
#                         d_x: Callable) -> Tuple[torch.Tensor, float]:
#     """
#     x_g: datapt generated by the generator
#     img_dir : path to the images on the data manifold
#     d_x: callable; metric on X to compute the distance between (x_g and x) for x in img_dir
#     """
#     # todo: test this function

#     min_d = np.inf
#     argmin = None
#     for i in range(len(dataset)):
#         # todo: make it random indexing
#         if i == n_datapts:
#             break

#         x = dataset[i]
#         curr_d = d_x(x_g, x)
        
#         if curr_d < min_d:
#             min_d = curr_d
#             argmin = x

#     return argmin, min_d

# - [ ] todo: old. remove
def compute_artifacts_from_batch(
    dataset: Dataset, 
    batch_xg: torch.Tensor, #batch of x's generated by G,
    n_datapts: int,
    d_x: Callable,
):
    """
    - [ ] todo: old. remove
    Args
    ----
    - data_dir : path to the directory containing all observed datapoint x's
    - G : generator module
    - latent_dim : dimension of the latent space G was paired with
    - batch_size : size of each batch used in sampling z in mini-batches, 
        until we collect the whole entired number of samples 
    - n_samples : number of samples to sample from Pz (to generated xg's and 
        to compute each xg's artifact/difference vector to the data manifold)
    - save_dir : path to directory to save the computed artifacts
    - save_artifacts : bool to indicate whether to save the artifacts (same dim as x's,
        i.e., an image dimension) to disk.

    Returns
    -------
    None

    """
    # todo: test this function
    # todo: make sure this works on xg that is a batch of samples (bs, 3, h, w)
    # batch_x_proj = estimate_projection(batch_xg, dataset)
    batch_x_proj = [ ] 
    for x_g in batch_xg:
        x_p, _ = estimate_projection(x_g, dataset, n_datapts, d_x) 
        batch_x_proj.append(x_p)
    batch_x_proj = torch.stack(batch_x_proj)

    batch_artifact = batch_x_proj - batch_xg
    return batch_artifact

# - [ ] todo: old. remove
def batch_compute_artifacts(
    data_dirpath,
    G, 
    latent_dim, 
    batch_size, 
    n_samples, 
    xsample_save_dir,
    artifacts_save_dir,
    save_xsamples: bool=False,
    save_artifacts: bool=False,
    ) -> Union[torch.Tensor,None]: # modified by cocoaaa (2022-07-25)
    # Use cuda if available
    use_gpu = torch.cuda.is_available()
    device = torch.device("cuda" if use_gpu else "cpu")

    # Load generator weights from checkpoint
    G.to(device)

    # Set G to eval mode
    G.eval()

    # Convert samples into numpy files and save images as PNG with max quality
    # gen_samples_dir = os.path.join(save_dir, sample_dir_name)
    if not os.path.exists(xsample_save_dir):
        os.mkdir(xsample_save_dir)
    if not os.path.exists(artifacts_save_dir):
        os.mkdir(artifacts_save_dir)

    for i in range( int(math.ceil(n_samples/batch_size)) ):
        # Fixed noise for sampling
        z = torch.randn( min( batch_size, int(n_samples-batch_size*i) ), latent_dim, 1, 1).to(device)

        # Generate samples and compute artifacts
        # todo: test this function

        with torch.no_grad():

            samples = G(z)
            if save_xsamples:
                save_samples_as_png(samples, xsample_save_dir, i*batch_size)
        
            # compute artifacts
            artifacts = compute_artifacts_from_batch(data_dirpath, G, latent_dim=latent_dim, batch_size=batch_size, n_samples=n_samples )
            if save_artifacts:
                save_samples_as_png(artifacts, artifacts_save_dir, i*batch_size)
            
            print(f'Computed {i*batch_size} artifacts...')
    print('Finished.')
    return


def compute_artifacts_of_samples_in(
    sample_dir: Path,
    dset: Dataset, 
    n_datapts: int,
    d_x: Callable,
    run_id: Optional[Union[int,str]]=None,
    save_trioplot: bool=False,
    save_trioplot_every: int=100,
):
    """
    todo: parallelize it on gpu 
    - use profiler to find out bottleneck

    - i think the bottleneck is: search for argmin (ie. estimate_projection)
    """

    image_load_xform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        ])

    # === Hyperparams
    # # ind = 100
    # n_datapts = 1000 #used to estimate the projection 
    # save_trioplot = False
    # save_trioplot_every = 100 # interval to save figure of the three plots (x_g, x_p, diff) 

    # === Run process 
    # model_name = 'DCGAN-B.1.3'
    model_name = sample_dir.stem
    print('='*30)
    print('Gen. Model: ', model_name)
    run_id = run_id or now2str()
    # Create output dirs for artifacts and artifact-trio plots
    out_root_dir = Path(f'../../outs/{run_id}')
    out_root_dir.mkdir(parents=True, exist_ok=True)
 
    out_dir = out_root_dir/f'Artifacts-{n_datapts}'/model_name
    out_dir.mkdir(parents=True, exist_ok=True)
    
    out_dir_trioplot = out_root_dir/ f'ArtifactPlots-{n_datapts}' / model_name
    out_dir_trioplot.mkdir(parents=True, exist_ok=True)
    
    print('Saving to: ', out_dir)
    for i, x_g_fp in enumerate(sample_dir.iterdir()):
        if not (x_g_fp.is_file() and x_g_fp.suffix == '.png'):
            continue
        #  if i>0: break #debug

        # load x_g
        x_g = image_load_xform(Image.open(x_g_fp))
        
        # compute x_proj and artifact
        x_proj, min_d = estimate_projection(x_g, dset,n_datapts, d_x=d_x )
        artifact = x_proj - x_g
        save_tanhtimgs_as_png(torch.stack([artifact]), out_dir, i)

        # plot the trio of (x_g, x_p, artifact)
        if save_trioplot and (i+1)%save_trioplot_every  == 0:
            npimgs2plot = [tanh_timg2npimg(t) for t in [x_g, x_proj, artifact]]
            fig, ax = show_npimgs(
                npimgs2plot,
                title=f'x_G, x_p, Artifact (min_d: {min_d:.3f}, n_samples: {n_datapts})', 
                nrows=1);
    #         todo: set asubfolder by model name
    #         todo: also apply the image range shifting before writinf  to disk?
    #         see generate.py 's save image function

            fig.savefig(out_dir_trioplot/f'x_g_{i}_trioplot.png')

#         breakpoint()
        if (i+1)%100 == 0:
            print(i+1, end='...')
            

if __name__ == "__main__":
    # main()
    pass
    