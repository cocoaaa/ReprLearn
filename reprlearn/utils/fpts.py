# 2022-07-25
# hayley's code for computing artifact of a generative model
# GM = (Generator, Prior P_z) where G: Z -> X whose domain Z has the structure 
# in that its datapoints/masses are distributed according to the prob. distributionP_z

# General modules
import time
from typing import Union, Optional, Callable, Tuple, List, Iterable, Dict, Any
from genericpath import exists
import os, math, argparse
from pathlib import Path
# Imaging/ scientific modules
import numpy as np
import PIL
from PIL import Image

# Pytorch modules
import torch
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms

# Lightning module
from IPython.core.debugger import set_trace as breakpoint

from reprlearn.utils.misc import now2str, is_img_fp, read_image_as_tensor
from reprlearn.utils.np import show_npimgs
from reprlearn.utils.dists import squared_l2_dist
from reprlearn.visualize.utils import show_timgs

### >>> Helper
# scale conversions
# e.g., tanh image (-1.,1.) to 01timg (0., 1.) or to npimg in uint8[0,255]
def tanh_timg2npimg(timg: torch.Tensor):
    """Given a torch tensor `timg` (nc, h, w) in range [-1., 1.],
    scale each value x_in to: [0.,1.]
    
    Assume timg is in range [-1,1] (e.g., an rgb image generated by a generator
    whose last layer is tanh so that each pixel is squished to [-1,1].
    Use it to:
    (i) rescale [-1,1] to [0.,1.] and
    (ii) then to unit8 [0,255]
    so that it is properly scaled for plt.imshow() 
    """
    std = 0.5
    mean = 0.5
    timg = (timg.permute(1, 2, 0).cpu().numpy()*std) + mean
    npimg = np.uint8(timg*255.0) 
    
    return npimg


def save_tanhtimgs_as_png(timgs: Union[torch.Tensor, List], 
                        out_dir:Union[str,Path], 
                        start_index:int):
    """Save each tensor in batch_tsamples in [0.,1.] to a png image
    as `save_loc`/{start_index + i}.png
    """
    std = 0.5
    mean = 0.5
    timgs = ((timgs * std) + mean).cpu() 
    save_01timgs_as_png(timgs, out_dir, start_index) 
    

def save_01timgs_as_png(timgs: Union[torch.Tensor, List], 
                        out_dir:Union[str,Path], 
                        start_index:int):
    """Save each tensor in batch_tsamples in [0.,1.] to a png image
    as `save_loc`/{start_index + i}.png
    """
    for i in range(len(timgs)):
        index = i + start_index
        # img = (batch_timgs[i, :, :, :].permute(1, 2, 0).cpu().numpy()*std) + mean
        img = timgs[i, :, :, :].permute(1, 2, 0).cpu().numpy()

        img_pil = PIL.Image.fromarray(np.uint8(img*255.0))
        # img_pil.save(os.path.join(save_loc, "{}.png".format(index)), quality=95, subsampling=-1)
        img_pil.save(os.path.join(out_dir, "{}.png".format(index)))

    return
### <<< end Helpers

# def estimate_projection(
#     img_fp: Path
#     manifold: Iterable[torch.Tensor],
#     metric: Optional[Callable]=None,
#     # xform: Callable[[Image], Union[np.ndarray, torch.Tensor]],
# ) -> Tuple[torch.Tensor, float]:
#     """Find a point x_p in `dset` that is closest to `x_g` using distance metric of
#     `metric`
#     todo:
#     - [ ] "manifold" naming might be assuming extra structure. we are considering
#     only a set of datapts on the (true) data manifold which we have access through
#     the sample only
#     """
#     metric = metric or squared_l2_dist
    
#     argmin = None
#     d_min = np.inf
#     for x in manifold:
#         d_curr = metric(x_g, x)
#         if d_curr < d_min:
#             d_min = d_curr
#             argmin = x
#     return argmin, d_min.item()


def estimate_projection(
    x_g: torch.Tensor,
    manifold: Iterable[torch.Tensor],
    metric: Optional[Callable]=None,
) -> Tuple[int, torch.Tensor, float]:
    """Find a point x_p in `dset` that is closest to `x_g` using distance metric of
    `metric`
    todo:
    - [ ] "manifold" naming might be assuming extra structure. we are considering
    only a set of datapts on the (true) data manifold which we have access through
    the sample only
    """
    metric = metric or squared_l2_dist
    
    x_min = None
    argmin_idx = None
    d_min = np.inf
    for idx, x in enumerate(manifold):
        # print(idx, x)
        d_curr = metric(x_g, x)
        # print('d curr: ', d_curr)
        # print('d min: ', d_min)
        
        if d_curr < d_min:
            d_min = d_curr
            x_min = x
            argmin_idx = idx
            
    return argmin_idx, x_min, d_min.item()
        

def compute_artifact(
    x_g: torch.Tensor,
    manifold: Iterable[torch.Tensor],
    metric: Optional[Callable]=None
) -> torch.Tensor:
    """ Compute an artifact (diff. vector) of `x_g` wrt the reference manifold
    using the `metric` as the distance metric.
    Returns: artifact tensor of a := x_p - x_g
    
    """
    x_p, argmin_idx, d_min = estimate_projection(x_g, manifold, metric)
    return x_p - x_g


def estimate_projection_fp(
    x_g_fp: Path,
    manifold_fps: Iterable[Path],
    metric: Optional[Callable]=None,
) -> Tuple[Path, torch.Tensor, float]:
    """Find a point x_p in `dset` that is closest to `x_g` using distance metric of
    `metric`
    todo:
    - [ ] "manifold" naming might be assuming extra structure. we are considering
    only a set of datapts on the (true) data manifold which we have access through
    the sample only
    """
    metric = metric or squared_l2_dist
    
    x_g = read_image_as_tensor(x_g_fp)
    
    x_min = None
    argmin_fp = None
    d_min = np.inf
    for idx, fp in enumerate(manifold_fps):
        # print(idx, x)
        x = read_image_as_tensor(fp)
        d_curr = metric(x_g, x)
        # print('d curr: ', d_curr)
        # print('d min: ', d_min)
        
        if d_curr < d_min:
            d_min = d_curr
            x_min = x
            argmin_fp = fp
            
    return argmin_fp, x_min, d_min.item()


def compute_artifact_fp(
    x_fp: torch.Tensor,
    manifold_fps: Iterable[Path],
    metric: Optional[Callable]=None
) -> torch.Tensor:
    """ Compute an artifact (diff. vector) of `x_g` wrt the reference manifold
    using the `metric` as the distance metric.
    Returns: artifact tensor of a := x_p - x_g
    
    """
    x_g = read_image_as_tensor(x_fp)
    #todo -- here
    x_p, argmin_idx, d_min = estimate_projection_fp(x_g, manifold_fps, metric)
    return x_p - x_g 
        
def compute_artifacts_in(
    fake_img_dir: Path,
    manifold: Iterable[torch.Tensor],
    out_dir: Path,
    metric: Optional[Callable]=None,
    show_trioplot: bool=False,
) -> torch.Tensor:
    """Compute artifacts of each image in fake_img_dir and save to out_dir"""
    for i, fp in enumerate(fake_img_dir.iterdir()):
        if not is_img_fp(fp):
            continue
            
        x_g = read_image_as_tensor(fp)
        art = compute_artifact(x_g, manifold, metric) 
        
        # save art as an image: 
        # - apply scaling [-1.,1.] to [0., 1.]
        try:
            out_stem = int(fp.stem)
        except ValueError:
            out_stem = i
        save_tanhtimgs_as_png(torch.stack([art]), out_dir=out_dir, start_index=out_stem)
    
        # show x_g, x_p, art
        if show_trioplot:
            x_p, _ = estimate_projection(x_g, manifold, metric)
            show_timgs([x_g, x_p, art], titles=['x_g', 'x_p', 'artifact'],
                    title=fp.stem, nrows=1)
    print('Done computing artifacts for: ', fake_img_dir) 


def compute_artifacts(
    fake_img_dir: Path,
    manifold_dir: Path,
    out_dir: Path,
    metric: Optional[Callable]=None,
    size_manifold: Optional[int]=None,
    show_trioplot: bool=False,
    transforms: Optional[Callable]=None,
) -> torch.Tensor:
    """Compute artifacts of each image in fake_img_dir and save to out_dir"""
    
    size_manifold = size_manifold or np.inf # to use all images in manifold_dir
    
    # reference manifold
    ref_img_fps = (img_fp for (i, img_fp) in enumerate(manifold_dir.iterdir()) 
       if i < size_manifold and is_img_fp(img_fp))
    manifold = map(read_image_as_tensor, ref_img_fps)
    
    # compute artifacts
    for i, fp in enumerate(fake_img_dir.iterdir()):
        if not is_img_fp(fp):
            continue
            
        x_g = read_image_as_tensor(fp)
        #tdo: transform if not none
        
        art = compute_artifact(x_g, manifold, metric) 
        
        # save art as an image: 
        # - apply scaling [-1.,1.] to [0., 1.]
        try:
            out_stem = int(fp.stem)
        except ValueError:
            out_stem = i
        save_tanhtimgs_as_png(torch.stack([art]), out_dir=out_dir, start_index=out_stem)
    
        # show x_g, x_p, art
        if show_trioplot and i == 0:
            x_p, _ = estimate_projection(x_g, manifold, metric)
            show_timgs([x_g, x_p, art], titles=['x_g', 'x_p', 'artifact'],
                    title=fp.stem, nrows=1)
            
    # print('Done computing artifacts for: ', fake_img_dir) 
                             
# Batch version of estimate_projection
def estimate_projection_batch(x_g:torch.Tensor, 
                              dl_manifold: DataLoader,
                              device: Union[torch.device,str],
                              verbose:bool=False,
                              debug: bool=False
                             ) -> Dict[str, Any]:
    """ Given a query timg, find the closest point (tensor) in dl_manifold.
    Implemented with dataloader over the manifold dataset.
    Returns:
    a dictionary with keys: 
    - "min_fp"(Path), 
    - "min_x" (torch.Tensor)
    - "min_dist" (float)
    """
    x_g = x_g.to(device)
    bs = dl_manifold.batch_size
    min_fp = None
    min_idx = None
    min_x = None
    min_dist = np.inf
    if verbose:
        print(f'x_g device: {x_g.device}')
    for batch_id, (batch_x, _) in enumerate(dl_manifold):
        
        batch_x = batch_x.to(device)
        
        if verbose and batch_id == 0:
            print(f'batch_x device: {batch_x.device}')

        start_idx = batch_id * bs
        
        # compute dist from x_g to each x in batch_x
        batch_dist =  torch.sum((x_g - batch_x) ** 2,
                                dim=(1,2,3)
                                )
    #     print(f'batch_dist shape: {batch_dist.shape}') #should be: (bs,)
        
        best_inner_idx = torch.argmin(batch_dist, dim=0).item()
                # current candidate
        curr_min_idx = start_idx + best_inner_idx
        curr_min_x = batch_x[best_inner_idx]
        curr_min_dist = batch_dist[best_inner_idx].item()
        
        # update if better:
        if curr_min_dist < min_dist:
            min_idx = curr_min_idx
            min_x = curr_min_x
            min_dist = curr_min_dist
            if verbose:
                print(f'Updated to new min_dist: {min_dist}')
            
        if batch_id == 0 and debug:
            show_timgs(batch_x, titles=batch_dist.numpy());
            
    # get the filepath to the "closest" point 
    min_fp = dl_manifold.dataset.df['img_fp'].iloc[min_idx] 
    
    if verbose:
        print(f'min_idx: {min_idx}')
        print(f'min_fp: {min_fp}')
        print(f'min_x: {min_x}')
        print(f'min_dist: {min_dist}')
        
    return {
        "min_fp": min_fp,
        "min_x": min_x,
        "min_dist": min_dist
    }

    # temp; to debug
# def process(df: pd.DataFrame,
#             device: Union[torch.Device, str],
#             print_every: int,
#            ):
#     start = time.time()
    
#     proj_fps = [ ] 
#     start_index = df.index[0]
#     end_index = df.index[-1]
#     n_total = len(df)
#     logger.info(f"RUN: Processing img_fps in df: {start_index} to {end_index}...")

#     for i, x_g_fp in enumerate(df['img_fp']):

#         if (i+1)%print_every == 0:
#             logger.info(f'{i+1}th image: {(i+1)*100/n_total:.2f} % ...')

#         fam_name = df['fam_name'].iloc[i]
#         # no need to process reals:
#         if fam_name == 'real':
#             min_fp = x_g_fp
#         else:
#             x_g = xform_rgb(load_pil_img(x_g_fp))       ## todo: xform_rgb vs. xform_freq
#             result = estimate_projection_batch(x_g, 
#                                                dl_manifold=real_dl_rgb, ## todo: real_dl_rgb vs real_dl_freq
#                                               device=device)
#             min_fp = result['min_fp']
#             # min_dist = result['min_dist']
#         proj_fps.append(min_fp)

#     # done:
#     df['proj_fp'] = proj_fps
#     end = time.time()
#     logger.info(f'Done: computing proj_fp for images in df_{mode}!')
#     logger.info(f'Took: {(end-start) / 60.} mins; size manifold={SIZE_MANIFOLD}; n_img_fps={n_total}')
    
#     # save:
#     dset_name = 'gm256'
#     feature_space = 'rgb'  #'fft'
#     df.to_csv(f'df-{mode}-{start_index}-{end_index}-with-proj-{feature_space}-{dset_name}-onek-{now2str()}.csv')
#     logger.info(f'Saved processed df: with proj_fp for df_{mode}!')
#     logger.info(f'=== Done: art-{feature_space} for  df_{mode}: {start_index}:{end_index} ===')
    


          
          
    
    

# def estimate_projection_v1(x_g:torch.Tensor, img_dir:Path, d_x: Callable) -> Tuple[torch.Tensor, float]:
#     """
#     x_g: datapt generated by the generator
#     img_dir : path to the images on the data manifold
#     d_x: callable; metric on X to compute the distance between (x_g and x) for x in img_dir
#     """
#     # todo: test this function

#     min_d = np.inf
#     argmin = None
#     for img_fp in img_dir.iterdir():
#         x = read_image_as_tensor(img_fp)
#         curr_d = d_x(x_g, x)
        
#         if curr_d < min_d:
#             min_d = curr_d
#             argmin = x
#     return argmin, min_d

# def estimate_projection_v2(x_g:torch.Tensor, 
#                         dataset: Dataset, 
#                         n_datapts: int,
#                         d_x: Callable) -> Tuple[torch.Tensor, float]:
#     """
#     x_g: datapt generated by the generator
#     img_dir : path to the images on the data manifold
#     d_x: callable; metric on X to compute the distance between (x_g and x) for x in img_dir
#     """
#     # todo: test this function

#     min_d = np.inf
#     argmin = None
#     for i in range(len(dataset)):
#         # todo: make it random indexing
#         if i == n_datapts:
#             break

#         x = dataset[i]
#         curr_d = d_x(x_g, x)
        
#         if curr_d < min_d:
#             min_d = curr_d
#             argmin = x

#     return argmin, min_d

# - [ ] todo: old. remove
# def compute_artifacts_from_batch(
#     dataset: Dataset, 
#     batch_xg: torch.Tensor, #batch of x's generated by G,
#     n_datapts: int,
#     d_x: Callable,
# ):
#     """
#     - [ ] todo: old. remove
#     Args
#     ---

#     Returns
#     -------

#     """
#     # todo: test this function
#     # todo: make sure this works on xg that is a batch of samples (bs, 3, h, w)
#     # batch_x_proj = estimate_projection(batch_xg, dataset)
#     batch_x_proj = [ ] 
#     for x_g in batch_xg:
#         x_p, _ = estimate_projection(x_g, dataset, n_datapts, d_x) 
#         batch_x_proj.append(x_p)
#     batch_x_proj = torch.stack(batch_x_proj)

#     batch_artifact = batch_x_proj - batch_xg
#     return batch_artifact

# # - [ ] todo: old. remove
# def batch_compute_artifacts(
#     data_dirpath,
#     G, 
#     latent_dim, 
#     batch_size, 
#     n_samples, 
#     xsample_save_dir,
#     artifacts_save_dir,
#     save_xsamples: bool=False,
#     save_artifacts: bool=False,
#     ) -> Union[torch.Tensor,None]: # modified by cocoaaa (2022-07-25)
#     # Use cuda if available
#     use_gpu = torch.cuda.is_available()
#     device = torch.device("cuda" if use_gpu else "cpu")

#     # Load generator weights from checkpoint
#     G.to(device)

#     # Set G to eval mode
#     G.eval()

#     # Convert samples into numpy files and save images as PNG with max quality
#     # gen_samples_dir = os.path.join(save_dir, sample_dir_name)
#     if not os.path.exists(xsample_save_dir):
#         os.mkdir(xsample_save_dir)
#     if not os.path.exists(artifacts_save_dir):
#         os.mkdir(artifacts_save_dir)

#     for i in range( int(math.ceil(n_samples/batch_size)) ):
#         # Fixed noise for sampling
#         z = torch.randn( min( batch_size, int(n_samples-batch_size*i) ), latent_dim, 1, 1).to(device)

#         # Generate samples and compute artifacts
#         # todo: test this function

#         with torch.no_grad():

#             samples = G(z)
#             if save_xsamples:
#                 save_samples_as_png(samples, xsample_save_dir, i*batch_size)
        
#             # compute artifacts
#             artifacts = compute_artifacts_from_batch(data_dirpath, G, latent_dim=latent_dim, batch_size=batch_size, n_samples=n_samples )
#             if save_artifacts:
#                 save_samples_as_png(artifacts, artifacts_save_dir, i*batch_size)
            
#             print(f'Computed {i*batch_size} artifacts...')
#     print('Finished.')
#     return


def compute_artifacts_of_samples_in(
    sample_dir: Path,
    dset: Dataset, 
    n_datapts: int,
    d_x: Callable,
    run_id: Optional[Union[int,str]]=None,
    save_trioplot: bool=False,
    save_trioplot_every: int=100,
):
    """
    todo: parallelize it on gpu 
    - use profiler to find out bottleneck

    - i think the bottleneck is: search for argmin (ie. estimate_projection)
    """

    image_load_xform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        ])

    # === Hyperparams
    # # ind = 100
    # n_datapts = 1000 #used to estimate the projection 
    # save_trioplot = False
    # save_trioplot_every = 100 # interval to save figure of the three plots (x_g, x_p, diff) 

    # === Run process 
    # model_name = 'DCGAN-B.1.3'
    model_name = sample_dir.stem
    print('='*30)
    print('Gen. Model: ', model_name)
    run_id = run_id or now2str()
    # Create output dirs for artifacts and artifact-trio plots
    out_root_dir = Path(f'../../outs/{run_id}')
    out_root_dir.mkdir(parents=True, exist_ok=True)
 
    out_dir = out_root_dir/f'Artifacts-{n_datapts}'/model_name
    out_dir.mkdir(parents=True, exist_ok=True)
    
    out_dir_trioplot = out_root_dir/ f'ArtifactPlots-{n_datapts}' / model_name
    out_dir_trioplot.mkdir(parents=True, exist_ok=True)
    
    print('Saving to: ', out_dir)
    for i, x_g_fp in enumerate(sample_dir.iterdir()):
        if not (x_g_fp.is_file() and x_g_fp.suffix == '.png'):
            continue
        #  if i>0: break #debug

        # load x_g
        x_g = image_load_xform(Image.open(x_g_fp))
        
        # compute x_proj and artifact
        x_proj, min_d = estimate_projection(x_g, dset,n_datapts, d_x=d_x )
        artifact = x_proj - x_g
        save_tanhtimgs_as_png(torch.stack([artifact]), out_dir, i)

        # plot the trio of (x_g, x_p, artifact)
        if save_trioplot and (i+1)%save_trioplot_every  == 0:
            npimgs2plot = [tanh_timg2npimg(t) for t in [x_g, x_proj, artifact]]
            fig, ax = show_npimgs(
                npimgs2plot,
                title=f'x_G, x_p, Artifact (min_d: {min_d:.3f}, n_samples: {n_datapts})', 
                nrows=1);
    #         todo: set asubfolder by model name
    #         todo: also apply the image range shifting before writinf  to disk?
    #         see generate.py 's save image function

            fig.savefig(out_dir_trioplot/f'x_g_{i}_trioplot.png')

#         breakpoint()
        if (i+1)%100 == 0:
            print(i+1, end='...')
            

if __name__ == "__main__":
    # main()
    pass
    